\chapter{Statistics and Probability}
\thispagestyle{fancy}

\keyword{Probability} is a fundamental concept in mathematics and statistics that measures the likelihood of an event occurring. It is represented as a value between 0 and 1, where 0 indicates the event is impossible, 1 denotes certainty, and values between 0 and 1 represent various degrees of likelihood. In simple terms, probability quantifies how probable or likely it is for an event to happen based on the total number of possible outcomes. It helps us make informed decisions, predict outcomes, and understand uncertainty in various real-world scenarios, such as games of chance, weather forecasts, and medical diagnoses. To understand probability on a mathematical level, some definitions of terminology is needed. `\keyword{Changes}' is a common word used, which is somewhat akin to a guess of the probability of something occuring.

A \keyword{state} (or outcome) is particular condition that something is in at a specific time. A \keyword{system} is an activity, experiment, process, or model with states or outcomes that are typically subject to uncertainty. A \keyword{sample space} of an system is the set of all possible states of a system. An \keyword{event} (also may be referred to as a trial or measurement) is any subset or collection of states contained in the sample space of a system. An event is a \keyword{simple event} if it consists of exactly one state and a \keyword{compound event} if it consistst of more than one state.

\begin{defn}[Probability]{Probability}
An \keyword{probability} $p$ can be defined as the asymptotic frequency of a system in the state $s$ ($s \in \Omega$, where $\Omega$ is the sample space of the system) by the total number of occurrences of that state $N_s$ in the limit of an infinite number of events $N$.
    \begin{align}
        p(s) = \lim_{N\rightarrow\infty}\frac{N_s}{N} \\
	p(s) \in [0,1] \forall s \in \Omega
    \end{align}
For a system with $n$ states, the total probabilities of all states must normalize to one.
    \begin{align}
        \sum_{i=0}^{n}p(i) = \sum_{s \in \Omega}p(i) = \lim_{N\rightarrow\infty}\frac{1}{N}\sum_{i=0}^{n}N_i = 1
    \end{align}
A \keyword{Bayesian probability} is defined as a person's knowledge of the outcome of a trial, based on the evidence at their disposal - often accompanied by an associated error. A \keyword{model probability} is an assumption or guess for the probability given the possibility of an infinite number of trials.
\end{defn}

Some more useful concepts for modeling a system are the mean (average) and standard deviation. 

\begin{defn}[Mean \label{Mean Definition}]
	If $x_1, ..., x_N$ denotes N separate measurements of one quantity $x$, then we define the mean (or average) $\braket{x}$ as
	\begin{align}
		\braket{x} = \frac{1}{N}\sum_{i=1}^{N}x_i \label{mean equation}
	\end{align}
\end{defn}

\begin{defn}[Standard Deviation \label{Standard Deviation Definition}]
	If $x_1, ..., x_N$ denotes N separate measurements of one quantity $x$, then we define the standard deviation $\sigma_x$ as
	\begin{align}
		\sigma_x = \sqrt{\frac{1}{N-1}\sum_{i}(x_i-\braket{x})^2}
	\end{align}
\end{defn}

When dealing with \keyword{Bayesian probability}, there is typically an uncertainty associated with the measurements or functions.

\begin{defn}[Uncertainty \label{Uncertainty}]
	Suppose $x_0, ..., x_N$ denotes N separate measurements with associated uncertainties $\delta x_0, ..., \delta x_N$. If the measured values are used to compute some function $q(x_0, ..., x_N)$ and the uncertainties in $x_0, ..., x_N$ are independent and random, then the uncertainty in $q$ is
	\begin{align}
		\delta q = \sqrt{\sum_{i=0}^{N}\bigg(\frac{\partial q}{\partial x_i} \delta x_i\bigg)^2}.
	\end{align}
 It will always be true that 
 	\begin{align}
		\delta q \leq \sum_{i=0}^{N}\abs{\frac{\partial q}{\partial x_i}} \delta x_i.
	\end{align}
\end{defn}
