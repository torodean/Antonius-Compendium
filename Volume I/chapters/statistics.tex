\chapter{Statistics and Probability}
\thispagestyle{fancy}

\keyword{Probability} is a fundamental concept in mathematics and statistics that measures the likelihood of an event occurring. It is represented as a value between 0 and 1, where 0 indicates the event is impossible, 1 denotes certainty, and values between 0 and 1 represent various degrees of likelihood. In simple terms, probability quantifies how probable or likely it is for an event to happen based on the total number of possible outcomes. It helps us make informed decisions, predict outcomes, and understand uncertainty in various real-world scenarios, such as games of chance, weather forecasts, and medical diagnoses. To understand probability on a mathematical level, some definitions of terminology is needed.

A \keyword{state} (or outcome) is particular condition that something is in at a specific time. A \keyword{system} is an activity, experiment, process, or model with states or outcomes that are typically subject to uncertainty. A \keyword{sample space} of an system is the set of all possible states of a system. An \keyword{event} (also may be referred to as a trial or measurement) is any subset or collection of states contained in the sample space of a system. An event is a \keyword{simple event} if it consists of exactly one state and a \keyword{compound event} if it consistst of more than one state.

\begin{defn}[Probability]{Probability}
An \keyword{probability} $p$ can be defined as the asymptotic frequency of a system in the state $s$ ($s \in \Omega$, where $\Omega$ is the sample space of the system) by the total number of occurrences of that state $N_s$ in the limit of an infinite number of events $N$.
    \begin{align}
        p(s) = \lim_{N\rightarrow\infty}\frac{N_s}{N} \\
	p(s) \in [0,1] \forall s \in \Omega
    \end{align}
For a system with $n$ states, the total probabilities of all states must normalize to one.
    \begin{align}
        \sum_{i=0}^{n}p(i) = \sum_{s \in \Omega}p(i) = \lim_{N\rightarrow\infty}\frac{1}{N}\sum_{i=0}^{n}N_i = 1
    \end{align}
A \keyword{Bayesian probability} is defined as a person's knowledge of the outcome of a trial, based on the evidence at their disposal - often accompanied by an associated error. A \keyword{model probability} is an assumption or guess for the probability given the possibility of an infinite number of trials.
\end{defn}

Some more useful concepts for modeling a system are the mean (average), standard deviation, and standard deviation of the  mean. 

\begin{defn}[Mean \label{Mean Definition}]
	If $x_1, ..., x_N$ denotes N separate measurements of one quantity $x$, then we define the mean (or average) $\braket{x}$ as
	\begin{align}
		\braket{x} = \frac{1}{N}\sum_{i=1}^{N}x_i \label{mean equation}
	\end{align}
\end{defn}

\begin{defn}[Standard Deviation \label{Standard Deviation Definition}]
	If $x_1, ..., x_N$ denotes N separate measurements of one quantity $x$, then we define the standard deviation $\sigma_x$ as
	\begin{align}
		\sigma_x = \sqrt{\frac{1}{N-1}\sum_{i}(x_i-\braket{x})^2}
	\end{align}
\end{defn}

The standard deviation of the mean can then be found by combining definitions \ref{Standard Deviation Definition} and \ref{Mean Definition}. First, we start by squaring (\ref{mean equation}) to get
	\begin{align}
	\braket{x}^2 = \bigg[\frac{1}{N}\sum_{i=1}^{N}x_i\bigg]^2
\end{align}
\begin{align}
	\sigma_{x} &= \sqrt{\frac{1}{N-1}\sum_{i}(x_i-\braket{x})^2} \\
			   &= \sqrt{\frac{1}{N-1}\sum_{i}(x_i^2-2x_i\braket{x}+\braket{x}^2)}
\end{align}